Sawwalakhe Altamash:
# ğŸ“¦ Import necessary libraries
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler

# ------------------------------------------------
# ğŸš¢ TASK 1: Drop Missing Values - Titanic Dataset
# ------------------------------------------------
print("\nğŸ“Œ TASK 1: Drop Missing Values (Titanic)\n")

titanic = sns.load_dataset('titanic')
print("ğŸ” Missing values before drop:\n", titanic.isnull().sum())
titanic_dropped = titanic.dropna()
print("\nâœ… Missing values after drop:\n", titanic_dropped.isnull().sum())

# ------------------------------------------------
# ğŸš¢ TASK 2: Fill Missing Values - Titanic Dataset
# ------------------------------------------------
print("\nğŸ“Œ TASK 2: Fill Missing Values (Titanic)\n")

titanic = sns.load_dataset('titanic')  # Reload original

# Fill missing age with median
titanic['age'] = titanic['age'].fillna(titanic['age'].median())

# Fill embarked with mode
titanic['embarked'] = titanic['embarked'].fillna(titanic['embarked'].mode()[0])

# Fill deck with "Unknown"
titanic['deck'] = titanic['deck'].fillna('Unknown')

print("âœ… Missing values after filling:\n", titanic.isnull().sum())

# ------------------------------------------------
# ğŸš¢ TASK 3: Label Encode Categorical Columns
# ------------------------------------------------
print("\nğŸ“Œ TASK 3: Label Encoding (Titanic)\n")

le = LabelEncoder()
categorical_cols = titanic.select_dtypes(include='object').columns

for col in categorical_cols:
    titanic[col] = titanic[col].astype(str)
    titanic[col] = le.fit_transform(titanic[col])

print("âœ… Encoded Titanic dataset (first 5 rows):\n", titanic.head())

# ------------------------------------------------
# ğŸŒ¸ TASK 4: Normalize & Standardize - Iris Dataset
# ------------------------------------------------
print("\nğŸ“Œ TASK 4: Normalize & Standardize (Iris)\n")

iris = sns.load_dataset('iris')
iris_features = iris.drop('species', axis=1)

# Min-Max Normalization
minmax_scaler = MinMaxScaler()
iris_normalized = pd.DataFrame(minmax_scaler.fit_transform(iris_features), columns=iris_features.columns)
print("âœ… Normalized Iris Dataset (first 5 rows):\n", iris_normalized.head())

# Standardization
standard_scaler = StandardScaler()
iris_standardized = pd.DataFrame(standard_scaler.fit_transform(iris_features), columns=iris_features.columns)
print("\nâœ… Standardized Iris Dataset (first 5 rows):\n", iris_standardized.head())

print("\nğŸ“ Min values:\n", iris_features.min())
print("\nğŸ“ Max values:\n", iris_features.max())

# ------------------------------------------------
# ğŸŒ¸ TASK 5: Boxplot of Iris Dataset
# ------------------------------------------------
print("\nğŸ“Œ TASK 5: Boxplot (Iris)\n")

plt.figure(figsize=(10, 6))
sns.boxplot(data=iris_features)
plt.title("ğŸ“¦ Boxplot of Iris Features")
plt.show()

# ------------------------------------------------
# ğŸŒ¸ TASK 6: Correlation Matrix - Iris Dataset
# ------------------------------------------------
print("\nğŸ“Œ TASK 6: Correlation Matrix (Iris)\n")

plt.figure(figsize=(8, 6))
sns.heatmap(iris_features.corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("ğŸ”— Correlation Matrix - Iris Dataset")
plt.show()

# ------------------------------------------------
# ğŸŒ¸ TASK 7: Count Plot of Species - Iris Dataset
# ------------------------------------------------
print("\nğŸ“Œ TASK 7: Count Plot (Iris Species)\n")

plt.figure(figsize=(6, 4))
sns.countplot(data=iris, x='species', hue='species', palette='Set2', legend=False)
plt.title("ğŸ”¢ Count of Each Species in Iris Dataset")
plt.xlabel("Species")
plt.ylabel("Count")
plt.show()

# ğŸš¢ Titanic & ğŸŒ¸ Iris Dataset Analysis Project

This project includes data preprocessing, visualization, and encoding tasks using the Titanic and Iris datasets. It demonstrates essential data analysis and machine learning preparation steps using Python libraries like Pandas, NumPy, Seaborn, and Scikit-learn.

---

## ğŸ“ Datasets Used

- Titanic Dataset: Contains information about passengers on the Titanic.
- Iris Dataset: Contains data about three species of Iris flowers.

---

## âœ… Tasks Overview

### ğŸ”¹ Task 1: Dropping Missing Values (Titanic)
- Load the Titanic dataset.
- Check for missing values.
- Drop all rows with missing data using dropna().

### ğŸ”¹ Task 2: Filling Missing Values (Titanic)
- Fill missing values in:
  - age with median
  - embarked with mode
  - deck with a custom value like "Unknown"

### ğŸ”¹ Task 3: Label Encoding (Titanic)
- Convert categorical columns (sex, embarked, etc.) to numeric using LabelEncoder.

---

### ğŸ”¹ Task 4: Normalizing and Standardizing (Iris)
- Load the Iris dataset.
- Apply MinMaxScaler for normalization (range 0â€“1).
- Apply StandardScaler for standardization (mean=0, std=1).

### ğŸ”¹ Task 5: Boxplot Visualization (Iris)
- Use Seaborn's boxplot() to visualize the spread and outliers in features like sepal length, petal width, etc.

### ğŸ”¹ Task 6: Correlation Matrix Plot (Iris)
- Generate a heatmap using sns.heatmap() to display correlations between the numeric features.

### ğŸ”¹ Task 7: Count Plot of Species (Iris)
- Create a count plot with sns.countplot() to show the number of samples for each flower species.

---

## ğŸ›  Libraries Used

- pandas
- numpy
- seaborn
- matplotlib.pyplot
- sklearn.preprocessing

---

## ğŸ“Š Visualizations

- Boxplots: For spotting outliers and understanding distributions.
- Heatmaps: For visualizing feature correlations.
- Countplots: For class frequency distribution.

---

## ğŸ“Œ How to Run

1. Install dependencies:
   ```bash
   pip install pandas numpy seaborn matplotlib scikit-learn
